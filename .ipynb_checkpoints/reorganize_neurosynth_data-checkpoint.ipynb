{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorganize files\n",
    "\n",
    "I ran this with the notebook in the neurosynth_folder, then moved it after. That's why all of the paths are relative.\n",
    "\n",
    "Also, I skipped version 0.2 because the files were formatted differently and I didn't think it was worth the effort to reorganize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_files = {\n",
    "    \"current_data/database.txt\": \"data-neurosynth_version-7_database.tsv.gz\",\n",
    "    \"data_0.6.July_2015/database.txt\": \"data-neurosynth_version-6_database.tsv.gz\",\n",
    "    \"data_0.5.February_2015/database.txt\": \"data-neurosynth_version-5_database.tsv.gz\",\n",
    "    \"data_0.4.September_2014/database.txt\": \"data-neurosynth_version-4_database.tsv.gz\",\n",
    "    \"data_0.3.April_2014/database.txt\": \"data-neurosynth_version-3_database.tsv.gz\",\n",
    "    # \"data_0.2.May_2013/database.txt\": \"data-neurosynth_version-2_database.tsv.gz\",\n",
    "}\n",
    "feature_files = {\n",
    "    \"current_data/features.txt\": {\n",
    "        \"database\": \"data-neurosynth_version-7_database.tsv.gz\",\n",
    "        \"vocab\": \"data-neurosynth_vocab-terms_version-7_vocabulary.txt\",\n",
    "        \"ids\": \"data-neurosynth_version-7_ids.txt\",\n",
    "        \"features\": \"data-neurosynth_source-abstract_vocab-terms_type-tfidf_version-7_features.npz\",\n",
    "    },\n",
    "    \"data_0.6.July_2015/features.txt\": {\n",
    "        \"database\": \"data-neurosynth_version-6_database.tsv.gz\",\n",
    "        \"vocab\": \"data-neurosynth_vocab-terms_version-6_vocabulary.txt\",\n",
    "        \"ids\": \"data-neurosynth_version-6_ids.txt\",\n",
    "        \"features\": \"data-neurosynth_source-abstract_vocab-terms_type-tfidf_version-6_features.npz\",\n",
    "    },\n",
    "    \"data_0.5.February_2015/features.txt\": {\n",
    "        \"database\": \"data-neurosynth_version-5_database.tsv.gz\",\n",
    "        \"vocab\": \"data-neurosynth_vocab-terms_version-5_vocabulary.txt\",\n",
    "        \"ids\": \"data-neurosynth_version-5_ids.txt\",\n",
    "        \"features\": \"data-neurosynth_source-abstract_vocab-terms_type-tfidf_version-5_features.npz\",\n",
    "    },\n",
    "    \"data_0.4.September_2014/features.txt\": {\n",
    "        \"database\": \"data-neurosynth_version-4_database.tsv.gz\",\n",
    "        \"vocab\": \"data-neurosynth_vocab-terms_version-4_vocabulary.txt\",\n",
    "        \"ids\": \"data-neurosynth_version-4_ids.txt\",\n",
    "        \"features\": \"data-neurosynth_source-abstract_vocab-terms_type-tfidf_version-4_features.npz\",\n",
    "    },\n",
    "    \"data_0.3.April_2014/features.txt\": {\n",
    "        \"database\": \"data-neurosynth_version-3_database.tsv.gz\",\n",
    "        \"vocab\": \"data-neurosynth_vocab-terms_version-3_vocabulary.txt\",\n",
    "        \"ids\": \"data-neurosynth_version-3_ids.txt\",\n",
    "        \"features\": \"data-neurosynth_source-abstract_vocab-terms_type-tfidf_version-3_features.npz\",\n",
    "    },\n",
    "    # \"data_0.2.May_2013/features.txt\": {\n",
    "    #     \"database\": \"data-neurosynth_version-2_database.tsv.gz\",\n",
    "    #     \"vocab\": \"data-neurosynth_vocab-terms_version-2_vocabulary.tsv\",\n",
    "    #     \"ids\": \"data-neurosynth_version-2_ids.tsv\",\n",
    "    #     \"features\": \"data-neurosynth_source-abstract_vocab-terms_type-tfidf_version-2_features.npz\",\n",
    "    # },\n",
    "}\n",
    "topic_feature_files = {\n",
    "    \"topics/v5-topics/analyses/v5-topics-50.txt\": {\n",
    "        \"database\": \"data-neurosynth_version-7_database.tsv.gz\",\n",
    "        \"vocab\": \"data-neurosynth_vocab-LDA50_version-7_vocabulary.txt\",\n",
    "        \"ids\": \"data-neurosynth_version-7_ids.txt\",\n",
    "        \"features\": \"data-neurosynth_source-abstract_vocab-LDA50_type-weight_version-7_features.npz\",\n",
    "    },\n",
    "    \"topics/v5-topics/analyses/v5-topics-100.txt\": {\n",
    "        \"database\": \"data-neurosynth_version-7_database.tsv.gz\",\n",
    "        \"vocab\": \"data-neurosynth_vocab-LDA100_version-7_vocabulary.txt\",\n",
    "        \"ids\": \"data-neurosynth_version-7_ids.txt\",\n",
    "        \"features\": \"data-neurosynth_source-abstract_vocab-LDA100_type-weight_version-7_features.npz\",\n",
    "    },\n",
    "    \"topics/v5-topics/analyses/v5-topics-200.txt\": {\n",
    "        \"database\": \"data-neurosynth_version-7_database.tsv.gz\",\n",
    "        \"vocab\": \"data-neurosynth_vocab-LDA200_version-7_vocabulary.txt\",\n",
    "        \"ids\": \"data-neurosynth_version-7_ids.txt\",\n",
    "        \"features\": \"data-neurosynth_source-abstract_vocab-LDA200_type-weight_version-7_features.npz\",\n",
    "    },\n",
    "    \"topics/v5-topics/analyses/v5-topics-400.txt\": {\n",
    "        \"database\": \"data-neurosynth_version-7_database.tsv.gz\",\n",
    "        \"vocab\": \"data-neurosynth_vocab-LDA400_version-7_vocabulary.txt\",\n",
    "        \"ids\": \"data-neurosynth_version-7_ids.txt\",\n",
    "        \"features\": \"data-neurosynth_source-abstract_vocab-LDA400_type-weight_version-7_features.npz\",\n",
    "    },\n",
    "    \"topics/v4-topics/analyses/v4-topics-50.txt\": {\n",
    "        \"database\": \"data-neurosynth_version-6_database.tsv.gz\",\n",
    "        \"vocab\": \"data-neurosynth_vocab-LDA50_version-6_vocabulary.txt\",\n",
    "        \"ids\": \"data-neurosynth_version-6_ids.txt\",\n",
    "        \"features\": \"data-neurosynth_source-abstract_vocab-LDA50_type-weight_version-6_features.npz\",\n",
    "    },\n",
    "    \"topics/v4-topics/analyses/v4-topics-100.txt\": {\n",
    "        \"database\": \"data-neurosynth_version-6_database.tsv.gz\",\n",
    "        \"vocab\": \"data-neurosynth_vocab-LDA100_version-6_vocabulary.txt\",\n",
    "        \"ids\": \"data-neurosynth_version-6_ids.txt\",\n",
    "        \"features\": \"data-neurosynth_source-abstract_vocab-LDA100_type-weight_version-6_features.npz\",\n",
    "    },\n",
    "    \"topics/v4-topics/analyses/v4-topics-200.txt\": {\n",
    "        \"database\": \"data-neurosynth_version-6_database.tsv.gz\",\n",
    "        \"vocab\": \"data-neurosynth_vocab-LDA200_version-6_vocabulary.txt\",\n",
    "        \"ids\": \"data-neurosynth_version-6_ids.txt\",\n",
    "        \"features\": \"data-neurosynth_source-abstract_vocab-LDA200_type-weight_version-6_features.npz\",\n",
    "    },\n",
    "    \"topics/v4-topics/analyses/v4-topics-400.txt\": {\n",
    "        \"database\": \"data-neurosynth_version-6_database.tsv.gz\",\n",
    "        \"vocab\": \"data-neurosynth_vocab-LDA400_version-6_vocabulary.txt\",\n",
    "        \"ids\": \"data-neurosynth_version-6_ids.txt\",\n",
    "        \"features\": \"data-neurosynth_source-abstract_vocab-LDA400_type-weight_version-6_features.npz\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganize_database_file(in_file, out_file):\n",
    "    print(f\"Processing {in_file}\")\n",
    "    if op.isfile(out_file):\n",
    "        print(\"\\tSkipping\")\n",
    "        return\n",
    "    df = pd.read_table(in_file)\n",
    "    df = df.sort_values(by=\"id\")\n",
    "    df.to_csv(out_file, sep=\"\\t\", line_terminator=\"\\n\", index=False)\n",
    "    \n",
    "def reorganize_feature_file(in_file, dict_):\n",
    "    print(f\"Processing {in_file}\")\n",
    "    database_file = dict_[\"database\"]\n",
    "    vocab_file = dict_[\"vocab\"]\n",
    "    ids_file = dict_[\"ids\"]\n",
    "    features_file = dict_[\"features\"]\n",
    "    database = pd.read_table(database_file)\n",
    "    database_ids = sorted(list(set(database[\"id\"].astype(str))))\n",
    "    \n",
    "    if op.isfile(features_file):\n",
    "        print(\"\\tSkipping\")\n",
    "        return\n",
    "    \n",
    "    assert not op.isfile(vocab_file)\n",
    "\n",
    "    try:\n",
    "        original_df = pd.read_table(in_file, index_col=\"pmid\")\n",
    "    except ValueError:\n",
    "        original_df = pd.read_table(in_file, index_col=\"id\")\n",
    "    \n",
    "    original_df.index = original_df.index.astype(str)\n",
    "    feature_ids = original_df.index.tolist()\n",
    "    if op.isfile(ids_file):\n",
    "        ids_file_ids = np.genfromtxt(ids_file, dtype=str).tolist()\n",
    "    else:\n",
    "        ids_file_ids = sorted(feature_ids[:])\n",
    "    \n",
    "    in_ids_but_not_feature = list(set(ids_file_ids) - set(feature_ids))\n",
    "    in_feature_but_not_ids = list(set(feature_ids) - set(ids_file_ids))\n",
    "    in_database_but_not_feature = list(set(database_ids) - set(feature_ids))\n",
    "    in_feature_but_not_database = list(set(feature_ids) - set(database_ids))\n",
    "    if in_ids_but_not_feature:\n",
    "        raise Exception(f\"{len(in_ids_but_not_feature)} found in IDs file but not {in_file}\")\n",
    "    \n",
    "    if in_feature_but_not_ids:\n",
    "        raise Exception(f\"{len(in_feature_but_not_ids)} found in {in_file} but not IDs file\")\n",
    "        \n",
    "    if in_database_but_not_feature:\n",
    "        raise Exception(f\"{len(in_database_but_not_feature)} found in DB file but not {in_file}\")\n",
    "    \n",
    "    if in_feature_but_not_database:\n",
    "        raise Exception(f\"{len(in_feature_but_not_database)} found in {in_file} but not DB file\")\n",
    "    \n",
    "    # Ensure same order\n",
    "    original_df = original_df.loc[ids_file_ids]\n",
    "    \n",
    "    # Now split into data, vocab, and ids\n",
    "    feature_data = original_df.to_numpy()\n",
    "    feature_vocab = original_df.columns.tolist()\n",
    "    feature_ids = original_df.index.tolist()\n",
    "    \n",
    "    # Output vocab\n",
    "    with open(vocab_file, \"w\") as fo:\n",
    "        fo.write(\"\\n\".join(feature_vocab))\n",
    "    \n",
    "    # Convert to Compressed Sparse Column format sparse matrix\n",
    "    # and save to file\n",
    "    feature_data_sparse = sparse.csc_matrix(feature_data)\n",
    "    sparse.save_npz(features_file, feature_data_sparse, compressed=True)\n",
    "    \n",
    "    # Output IDS\n",
    "    if not op.isfile(ids_file):\n",
    "        with open(ids_file, \"w\") as fo:\n",
    "            fo.write(\"\\n\".join(feature_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing current_data/database.txt\n",
      "\tSkipping\n",
      "Processing data_0.6.July_2015/database.txt\n",
      "\tSkipping\n",
      "Processing data_0.5.February_2015/database.txt\n",
      "\tSkipping\n",
      "Processing data_0.4.September_2014/database.txt\n",
      "\tSkipping\n",
      "Processing data_0.3.April_2014/database.txt\n",
      "\tSkipping\n"
     ]
    }
   ],
   "source": [
    "for k, v in database_files.items():\n",
    "    reorganize_database_file(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing current_data/features.txt\n",
      "Processing data_0.6.July_2015/features.txt\n",
      "Processing data_0.5.February_2015/features.txt\n",
      "Processing data_0.4.September_2014/features.txt\n",
      "Processing data_0.3.April_2014/features.txt\n"
     ]
    }
   ],
   "source": [
    "for k, v in feature_files.items():\n",
    "    reorganize_feature_file(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topics/v5-topics/analyses/v5-topics-50.txt\n",
      "Processing topics/v5-topics/analyses/v5-topics-100.txt\n",
      "Processing topics/v5-topics/analyses/v5-topics-200.txt\n",
      "Processing topics/v5-topics/analyses/v5-topics-400.txt\n",
      "Processing topics/v4-topics/analyses/v4-topics-50.txt\n",
      "Processing topics/v4-topics/analyses/v4-topics-100.txt\n",
      "Processing topics/v4-topics/analyses/v4-topics-200.txt\n",
      "Processing topics/v4-topics/analyses/v4-topics-400.txt\n"
     ]
    }
   ],
   "source": [
    "for k, v in topic_feature_files.items():\n",
    "    reorganize_feature_file(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
